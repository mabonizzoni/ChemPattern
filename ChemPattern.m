(* ::Package:: *)

(* ::Section::Initialization:: *)
(*The Bonizzoni Group - LDA functions package*)


(* The following forces the automatic generation / overwriting of an .m package file from this file every time this file is saved. *)
SetOptions[InputNotebook[],AutoGeneratedPackage->Automatic]


(* ::Input::Initialization:: *)
BeginPackage["lda`"]

Unprotect[addLabels,filterVars,groupcontribs,heatmap,lda,pairwiseScatterPlot,pca,projectorLDA,outlierPCA,overview,removeOutliers,retainedInfo,selectVarSubsets];
ClearAll[addLabels,filterVars,groupcontribs,heatmap,lda,pairwiseScatterPlot,pca,projectorLDA,outlierPCA,overview,removeOutliers,retainedInfo,selectVarSubsets];


(* ::Input::Initialization:: *)
addLabels::usage="addLabels[ \!\(\*
StyleBox[\"matrix\",\nFontSlant->\"Italic\"]\)\!\(\*
StyleBox[\" \",\nFontSlant->\"Italic\"]\)]\naddLabels[ \!\(\*
StyleBox[\"matrix\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"rowLabels\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"columnLabels\",\nFontSlant->\"Italic\"]\)]\naddLabels[ \!\(\*
StyleBox[\"matrix\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"rowLabels\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"columnLabels\",\nFontSlant->\"Italic\"]\), \"TopLeft\" -> \!\(\*
StyleBox[\"spacer\",\nFontSlant->\"Italic\"]\)]";

filterVars::usage="filterVars[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)] starts an interactive session to explore variable removal from LDA analysis of \!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\). Move the threshold bar with the mouse to change the variable selection threshold.\n\nfilterVars[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"threshold\",\nFontSlant->\"Italic\"]\)] returns non-interactive results obtained by removing variables whose contribution is less than the indicated \!\(\*
StyleBox[\"threshold\",\nFontSlant->\"Italic\"]\).\n\nfilterVars[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"threshold\",\nFontSlant->\"Italic\"]\), output -> \"ReducedSet\"] returns a reduced data set obtained by removing variables whose contribution is less than the indicated \!\(\*
StyleBox[\"threshold\",\nFontSlant->\"Italic\"]\).";

groupcontribs::usage="groupcontribs[\!\(\*
StyleBox[\"eigensystem\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"numberofgroups\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"sensornames\",\nFontSlant->\"Italic\"]\)]\ngroupcontribs[\!\(\*
StyleBox[\"eigensystem\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"numberofgroups\",\nFontSlant->\"Italic\"]\)]\nThe function generates a bar chart of the contributions of each group of variables to the overall discrimination. Before summing, the contributions to each factor are weighted by the corresponding eigenvalue of the factor. This is needed so that a group that contributes a lot to an unimportant factor is still reported as unimportant in the overall discrimination.";

heatmap::usage="heatmap[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)] will produce a heat map plot of the entire dataset to quickly spot unevenness, data quality, obvious outlier points, and information distribution within each instrumental measurement. In the plot the data is presented by rows (samples) and columns (measurements). The data for each measurement type is standardized before plotting so the magnitudes of variation are comparable.\n\nFunction-specific options:\n\"sortedSet\" -> True  If this is set to False, then both the columns and the rows of the dataset are sorted alphabetically before plotting. The default value (True) does no sorting.\n\nThe function uses ArrayPlot to generate the graphics so it also takes general plotting function / Graphics options such as ColorFunction and ColorFunctionScaling, AspectRatio, Mesh, MeshStyle.";

lda::usage="lda[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)] carries out Linear Discriminant Analysis on dataset and returns the transformed data as factor scores (default), or other numerical / graphical results. Each row of dataset should contain a sample; the first column contains the class identifier for that sample.\nOptions:\napplyfunc (Identity, Standardize (default), Rescale, ...)\noutput (\"scores\", \"vartable\", \"varlist\", \"eigenvectors\", \"eigensystem\", \"2D\" (= 2D score plot), \"2DL\" (= 2D score and loading plots, default), \"3D\", \"3DL\")\nswapaxes (default = {False,False})\nellipsoidcolor (Automatic, True)\nconfidencelevel (default is 0.95 = 95% confidence)";

pairwiseScatterPlot::usage="pairwiseScatterPlot[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)] will produce scatter plots for each pair of variables against each other, overlaid with the coefficient of correlation for the pair\nThis function is most effective after some variable reduction, since generating all scatterplots in a large dataset can be very time consuming and lead to unreadable results.";

pca::usage="pca[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)] performs PCA analysis on the data in dataset after standardization. It takes most of the same options as the lda function";

projectorLDA::usage="projectorLDA[\!\(\*
StyleBox[\"originalDataSet\",\nFontSlant->\"Italic\"]\),(\"suffix to add to original data set labels\"),\!\(\*
StyleBox[\"datasetToBeProjected\",\nFontSlant->\"Italic\"]\),(\"suffix to add to projected data set labels\")]\nThis function projects points from the second data set according to the transformation ruls obtained by standard LDA on the first data set.";

outlierPCA::usage="outlierPCA[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\), <\!\(\*
StyleBox[\"options\",\nFontSlant->\"Italic\"]\)>] will try to automatically identify outliers using PCA scores, similar to using a threshold on the Mahalanobis distance.\n\n\!\(\*
StyleBox[\"Options\",\nFontWeight->\"Bold\"]\):\nmethod -> \"SinglePass\"   the classic one-pass method used so far (default)\nmethod -> \"Recursive\"    applies outlierPCA on its own results until the results no longer change\n\noutput ->\"Plots\"\tshows outlier score plots with potential outliers highlighted in red (default)\noutput ->\"Lists\"\treturns a structured list of retained and rejected points for each sample\noutput ->\"OutlierLists\"  returns a list of the numerical labels of the points deemed to be outliers for each sample set\noutput ->\"CleanedSet\"  returns a formatted data set from which potential outliers have been removed; this can be fed directly to e.g. pca or lda functions\n\ndimensions -> \!\(\*
StyleBox[\"dims\",\nFontSlant->\"Italic\"]\)  how many PCA components to use in the identification of outliers. The default is 2; no more than half the number of instrumental variables is allowed";

overview::usage="overview[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)] examines the quality of each instrumental measurement in \!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\) through a set of sparklines, one per measurement\n\noverview[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\), output -> \"Table\"] returns summary statistics on the measurements in \!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\) in tabular form\n";

removeOutliers::usage="removeOutliers[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)][{\"Sample1\", {1, 2, 4, ..}}, {\"Sample2\", {2, 5, 4, ..}}, ..]";

retainedInfo::usage="retainedInfo[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\)] calculates the % information retained as a function of filtering threshold\n\toutput -> \"Plot\"\treturns the data as a plot (default)\n\toutput -> \"List\"\t returns the results as a list of {\!\(\*
StyleBox[\"threshold\",\nFontSlant->\"Italic\"]\), % \!\(\*
StyleBox[\"information\",\nFontSlant->\"Italic\"]\)\!\(\*
StyleBox[\" \",\nFontSlant->\"Italic\"]\)\!\(\*
StyleBox[\"retained\",\nFontSlant->\"Italic\"]\)}";

selectVarSubsets::usage="selectVarSubsets[\!\(\*
StyleBox[\"dataset\",\nFontSlant->\"Italic\"]\), \!\(\*
StyleBox[\"criteria\",\nFontSlant->\"Italic\"]\)] generates a new dataset by selecting the measurements whose names match \!\(\*
StyleBox[\"criteria\",\nFontSlant->\"Italic\"]\).\n\nCriteria can be:\n\ta single string: selects all measurement whose names contains that string (e.g. selectVarSubsets[\!\(\*
StyleBox[\"data\",\nFontSlant->\"Italic\"]\), \"308\"])\n\tan Alternatives statement, using | (e.g. selectVarSubsets[\!\(\*
StyleBox[\"data\",\nFontSlant->\"Italic\"]\), \"308\" | \"450\"] selects measurements whose names contain EITHER 308 OR 450\n\tan Except statement (e.g. selectVarSubsets[\!\(\*
StyleBox[\"data\",\nFontSlant->\"Italic\"]\), Except[\"308\"]] selects all measurements EXCEPT those whose names contain 308.\n\ta list of criteria: selects those that match ALL criteria (e.g. selectVarSubsets[\!\(\*
StyleBox[\"data\",\nFontSlant->\"Italic\"]\), {\"3\", \"D\", Except[\"5\"]}] selects measurements whose names contain BOTH 3 and D, BUT NOT 5)";
selectVarSubsets::emptystring="One of the criteria contains an empty string (\"\"). Check your input.";


(* ::Section::Initialization::Closed:: *)
(*Implementation code below*)


(* ::Input::Initialization:: *)
Begin["`Private`"]


(* ::Section::Closed:: *)
(*addLabels: helper function to re-add row and column labels to a numbers-only data set*)


(* ::Text:: *)
(*If no labels are provided, then generic "row_n" and "column_n" labels will be generated.*)
(**)
(*If only one set of labels is provided, then they will be assigned to the rows or columns depending on which dimension of data they fit. If there is no match, then the function should RETURN UNEVALUATED with an error.*)
(**)
(*If two sets of labels are given, the function will try to detect whether the labels are given in order of row then column, or column then row, based on the dimensions of the numbers matrix and of the label vectors. If no match can be found, then the function will return unevaluated with an error.*)
(**)
(*If the data matrix is square, both function definitions would apply, so the first one in the code below will match first, so the first set of labels will be assumed to be the rows. If another result is desired, one can swap the order of the labels in the function call.*)


(* ::Input::Initialization:: *)
Options[addLabels]={"TopLeft"->""};
addLabels::dims="The dimensions of the labels provided do not match those of the data matrix.";

(* ============== TWO SETS =================== *)
(* TWO SETS: Labels given as rows, then columns *)
(* For square m matrices, this will match first *)
addLabels[m_?MatrixQ,set1_,set2_,OptionsPattern[]]/;(Length/@{set1,set2}==Dimensions[m]):=
Join[List/@Insert[set1,OptionValue["TopLeft"],1],Insert[m,set2,1],2]

(* TWO SETS: Labels given as columns, then rows *)
addLabels[m_?MatrixQ,set1_,set2_,OptionsPattern[]]/;(Length/@{set1,set2}==Reverse@Dimensions[m]):=
Join[List/@Insert[set2,OptionValue["TopLeft"],1],Insert[m,set1,1],2]
(* ============= END TWO SETS ================ *)


(* ============== ONE SET ===================== *)
(* ONE SET: ROW labels *)
addLabels[m_?MatrixQ,set1_,opts:OptionsPattern[]]/;(Length[set1]==First@Dimensions[m]):=
addLabels[m,set1,Array["col"~~ToString[#]&,Last@Dimensions@m],opts]

(* ONE SET: COLUMN labels *)
addLabels[m_?MatrixQ,set1_,opts:OptionsPattern[]]/;(Length[set1]==Last@Dimensions[m]):=
addLabels[m,Array["row"~~ToString[#]&,Length@m],set1,opts]

(* ONE SET: the length of the labels does not match either dimension of m *)
addLabels[m_?MatrixQ,set1_,OptionsPattern[]]:=""/;
(Thread[Length[set1]!=Dimensions[m]];Message[addLabels::dims])
(* ============== END ONE SET ================ *)


(* ============== NO LABELS ================ *)
(* No labels given: automatic generated a set from dimensions *)
addLabels[m_?MatrixQ,OptionsPattern[]]:=
Join[
List/@Insert[Array["row"~~ToString[#]&,Length@m],OptionValue["TopLeft"],1],
Insert[m,Array["col"~~ToString[#]&,Last@Dimensions@m],1],
2
]
(* ============== END NO LABELS ============= *)

(* ============ ERROR HANDLER =============== *)
(* Since the definitions above did not match, the dimensions of the two label sets *)(* must be mismatched to those of the m matrix: *)
addLabels[m_?MatrixQ,set1_,set2_,OptionsPattern[]]:=""/;Message[addLabels::dims]


(* ::Section::Initialization::Closed:: *)
(*lda: our implementation of LDA*)


(* ::Subsection::Initialization:: *)
(*Steps accomplished by the code below, in order:*)


(* ::Text::Initialization:: *)
(*check whether to normalize full data set column-wise*)
(*generate a series of subsets by using the labels in the first column to gather data by its class*)
(*calculate within class scatter for each class (Swi) and sum them up to give total within-class scatter (Sw): \!\(\*UnderscriptBox[\(\[Sum]\), \(sets\)]\)\!\(\*UnderscriptBox[\(\[Sum]\), \(samples\ in\ a\ set\)]\)(x-Subscript[\!\(\*OverscriptBox[\(x\), \(_\)]\), set])\[CenterDot](x-Subscript[\!\(\*OverscriptBox[\(x\), \(_\)]\), set])^T*)
(*calculate between class scatter (Sb): \!\(\*UnderscriptBox[\(\[Sum]\), \(sets\)]\)(Subscript[\!\(\*OverscriptBox[\(x\), \(_\)]\), set]-Subscript[\[Mu], global])\[CenterDot](Subscript[\!\(\*OverscriptBox[\(x\), \(_\)]\), set]-Subscript[\[Mu], global])^T*)
(*solve eigensystem of matrix Sw^-1\[CenterDot]Sb*)
(*plot transformed dataset in 2D with tooltips*)
(*return eigensystem*)


(* ::Subsection::Initialization:: *)
(*Implementation*)


(* ::Input::Initialization:: *)
Options[lda]={applyfunc->Standardize,output->"2DL",ellipsoidcolor->Automatic,swapaxes->False,confidencelevel->0.95};

lda::outputoptions="The value `1` is not a valid plotting option. Valid options are: \"2DL\" (default), \"2D\", \"3DL\", \"3D\", \"scores\", \"eigenvectors\", \"eigensystem\", \"vartable\", \"varlist\".";
lda::swapaxesnotboolean="The value `1` is not a valid swapaxes option. Use only True / False or combinations thereof.";
lda::swapaxeslength="The value `1` given for the swapaxes option is not valid. Acceptable values are a single True / False, to be applied to all axes, or a list containing as many True/False values as there are axes in the requested plot.";
lda::ellcolor="The value `1` for the ellipsoidcolor option is not valid. Acceptable values are: Automatic, True, False. Automatic settings were used.";
lda::conflevel="`1` is an invalid value for the confidence level (0 < p < 1). The default 95% confidence level will be used instead.";

lda[matrix_?MatrixQ,OptionsPattern[]]:=Module[
{(* the definition below is important, although it looks silly!*)
(* If one used matrix directly in the function body, the VALUE of matrix would be substituted *)
(* everywhere BEFORE any further evaluation. the name of the pattern is not a proper variable!! *)
(* This is the reason why the standardization in place did not work before *)
dataset=matrix,

(* other local variables*)
hascolumnheaders,columnheaderlist,classlist,
partitioneddata,transformeddata,labeledtransformed,partitionedscores,
grandmean,clustermeans,Swi,Sw,Sb,
eigenvals,eigenvecs,
plotdata,readyforplot,
confidenceLevel,
ellipsoids2D,coloredellipsoids2D,
ellipsoids3D,coloredellipsoids3D,
(* this longer color list was introduced when I ran the acetate and chloride LDA, which had many groups and the function ran out of colors *)
colorlist=Join[ColorData[97,"ColorList"],Lighter@ColorData[97,"ColorList"],Lighter@ColorData[99,"ColorList"]]
},

(* Set the confidence level for ellipsoid plotting *)
(* The deafult value is 0.95 for 95% confidence *)
(* Incorrect values trigger a message, but the calculation continues anyway, using the default 95% confidence level *)
confidenceLevel=With[{cf=OptionValue["confidencelevel"]},If[NumericQ[cf]&&0<cf<1,cf,Message[lda::conflevel,cf];0.95]];

(* if column headers are present, extract them and assign them to columnheaderlist. *)
(* if not, create a generic columnheaderlist and add it to the top of the dataset *)
(* this simplifies manipulation later on because we can assume the presence of column headers *)
(* and don't need to repeatedly check, no matter whether the original data had them or not *)
(* Remember that from now on dataset[[1,1]] contains no intereseting data *)
If[VectorQ[dataset[[1,2;;]],NumberQ]==True,
hascolumnheaders=False;PrependTo[dataset,Join[{""},columnheaderlist=ToString/@Array["var",Last@Dimensions@dataset-1]]],
hascolumnheaders=True;columnheaderlist=dataset[[1,2;;]]
];

(* extract the class list from the first column in the dataset; remember that the first row is the column headers *)
classlist=DeleteDuplicates[dataset[[2;;,1]]];

(* Apply the applyfunc function to the numerical part of the dataset *)
(* applyfunction's default is Standardize *)
(* To do nothing, one can use Identity *)
(* Any appropriate custom standardizing function can be passed in *)
dataset[[2;;,2;;]]=OptionValue[applyfunc][dataset[[2;;,2;;]]];

(* Row headers are used as class labels to partition the data into the user-specified classes *)
(* The first row of dataset contains the column headers so it is ignored here *)
(* The class labels are then removed before assigning the list of partitioned datasets to partitioneddata *)
partitioneddata=GatherBy[dataset[[2;;]],First][[All,All,2;;]];

(* Calculate the within-cluster scatter by applying the Swi function to each cluster, and summing up each cluster's contribution *)
Swi[set_]:=Total[Map[Transpose[{#-Mean[set]}] . {#-Mean[set]}&,set]];
Sw=Total[Map[Swi,partitioneddata]];

(* Calculate the between-cluster scatter *)
(* In the case of a standardized dataset, the grand mean, i.e. the column-wise mean over the entire dataset should be exactly zero *)(* However it will typically calculate out to very small non-zero numbers at machine precision. To avoid accumulating inaccuracies, *)
(* the grand mean is chopped. If the dataset is not standardized, chopping has no significant effect *)
grandmean=Chop@Mean[dataset[[2;;,2;;]]];
clustermeans=Map[Mean,partitioneddata];
Sb=Total[Map[(Transpose[{#-grandmean}] . {#-grandmean}&),clustermeans]];

(* Maximize the Sb/Sw ratio by solving the equivalent eigenproblem *)
(* The Check[] wrapper around Inverse stops computation and returns if the inverse cannot be computed, e.g. for singular matrices *)
(*old Implementation:*)
(*{eigenvals,eigenvecs}=Chop@Eigensystem[Check[Inverse[Sw].Sb,Abort[],{Inverse::sing}]];*)
{eigenvals,eigenvecs}=Chop@Eigensystem[LinearSolve[Sw,Sb]];

(* Calculate data scores along the LDA dimensions *)
transformeddata=Chop[dataset[[2;;,2;;]] . Transpose@eigenvecs];

(* Add back the column and row headers to the transformed data *)
labeledtransformed=Prepend[dataset[[1]]][Transpose@Insert[Transpose@transformeddata,dataset[[2;;,1]],1]];

Which[

(********************)
(* Numerical output *)
(********************)

OptionValue[output]=="scores",(* Return the transformed data as labeled scores, e.g. for external plotting *)
Return[
Transpose@Prepend[
(* Add the ROW headers from the original dataset back in *)
Transpose@Prepend[
(* Add the factor number COLUMN headers *)
transformeddata,Array["F"<>ToString[#]&,Dimensions[transformeddata][[2]] ]
],
dataset[[All,1]]
]
],

OptionValue[output]=="vartable",(* Return a formatted table of the contributions of each variable to the first three factors *)
Return[
Style[
TableForm[Transpose@Round[100eigenvecs[[1;;3]]^2,1],TableHeadings->{columnheaderlist, {"F1","F2","F3"}},TableAlignments->Right],
FontFamily->"Arial",FontSize->14
]
],

OptionValue[output]=="varlist",(* Return the contributions of each variable to the first three factors as above, but WITHOUT formatting *)
Return[
Transpose@Join[{columnheaderlist}, Round[100eigenvecs^2,1]]
],

OptionValue[output]=="eigenvectors",(* Return eigenvector matrix *)
Return[eigenvecs],

OptionValue[output]=="eigensystem", (* Return the list: {eigenvalues,eigenvectors} *)
Return[{eigenvals,eigenvecs}],

(***************)
(* 2D PLOTTING *)
(***************)

OptionValue[output]=="2D"||OptionValue[output]=="2DL",(* 2D plot of results was requested *)
plotdata=labeledtransformed[[All,1;;3]];

(* Swap values along x or y axes if requested; default is to do nothing *)
Module[
{xflip,yflip},
Switch[Length@OptionValue[swapaxes],

0, (* Atomic expression, i.e. a single value was passed *)
Switch[OptionValue[swapaxes],
True,xflip=yflip=-1,(* swap both axes *)
False,xflip=yflip=1,(* don't swap any axis *)
_,(* incorrect option; throw error and return Null *)Message[lda::swapaxesnotboolean,OptionValue[swapaxes]];Return[]
],

1,(* a list with one element; this is ambiguous and may be a syntax error on the part of the user; throw error *)
Message[lda::swapaxeslength,OptionValue[swapaxes]];Return[],

2,(* a list of two values*)
If[Not[BooleanQ@OptionValue[swapaxes][[1]]&&BooleanQ@OptionValue[swapaxes][[2]]],Message[lda::swapaxesnotboolean,OptionValue[swapaxes]];Return[]];
xflip=If[OptionValue[swapaxes][[1]]===True,-1,1];
yflip=If[OptionValue[swapaxes][[2]]===True,-1,1],

_,(* too many parameters for a 2D plot; possibly ambiguous *)
Message[lda::swapaxeslength,OptionValue[swapaxes]];Return[]
];

plotdata=plotdata/.List[class_?StringQ,x_?NumberQ,y_?NumberQ]:>List[class,xflip x,yflip y]
];

(* The basic size / shape of the ellipsoids is dictated by the covariance of each replicate set - but their size must also be adjusted to take into consideration the desired confidence level *) (* The multiplier for p confidence level (0 < p < 1) in n dimensions is given by InverseCDF[ChiSquareDistribution[n], p] *)
(* So for instance for 95% in 2D: InverseCDF[ChiSquareDistribution[2], 0.95] = 5.991 i.e. around 6 "covariance units" *)
partitionedscores=GatherBy[plotdata[[2;;]],First][[All,All,2;;3]];
ellipsoids2D={Opacity[0],EdgeForm[{Darker@Gray}],Ellipsoid[Mean[#],InverseCDF[ChiSquareDistribution[2],confidenceLevel]Covariance[#]]}&/@partitionedscores;
coloredellipsoids2D=MapThread[
{Opacity[0],EdgeForm[{#2,AbsoluteThickness[2]}],Ellipsoid[Mean[#1],InverseCDF[ChiSquareDistribution[2],confidenceLevel]Covariance[#1]]}&,
{
partitionedscores,
colorlist[[1;;First@Dimensions@partitionedscores]]
}];

readyforplot=MapThread[Tooltip,{partitionedscores,classlist}];

Return[
If[OptionValue[output]=="2DL",GraphicsRow[#,ImageSize->Scaled[2/3]]&,Show[#[[1]],ImageSize->Scaled[1/3]]&]@
List[
(* 2D score plot *)
ListPlot[readyforplot,
Frame->True,Axes->False,FrameStyle->Directive[Black,FontSize->15],FrameLabel->{
Style["Factor 1 ("<>ToString[Round[100eigenvals[[1]]/Total@eigenvals,0.1]]<>"%)",FontSize->16,Blue],
Style["Factor 2 ("<>ToString[Round[100eigenvals[[2]]/Total@eigenvals,0.1]]<>"%)",FontSize->16,Red]
},
AspectRatio->1,PlotRange->All,PlotRangePadding->Scaled[0.10],
Epilog->Which[
OptionValue[ellipsoidcolor]===Automatic||OptionValue[ellipsoidcolor]===False,ellipsoids2D,
OptionValue[ellipsoidcolor]===True,coloredellipsoids2D,
True,Message[lda::ellcolor,OptionValue[ellipsoidcolor]];ellipsoids2D
]
],
If[OptionValue[output]=="2DL",
(* 2D loading plot *)
ListPlot[
MapThread[
(* old version: it included contributions in the labels, but it was too busy, and we often end up removing them anyway! *)
(*Labeled[100#1,Style[#2<>" "<>ToString@Round[100#1,1],Medium]]&,*)
(* new version only has measurement name; no longer includes the contributions *)
(* LabelVisibility priority calculated through Norm of the corresponding vector *)
(* this preferentially shows labels for contributions further away from the origin, i.e. more important *)
Labeled[100#1,Style[#2,Medium],LabelVisibility->Norm[#1]]&,
{Transpose[eigenvecs[[1;;2]]^2],columnheaderlist}
],
PlotStyle->Directive[Black,PointSize[0.025]],
(* The aspect ratio and plotrange definitions below make the plot square, while still adapting the plot range to the values being plotted *)
AspectRatio->1,PlotRange->{{0,105Max[Transpose[eigenvecs[[1;;2]]^2]]},{0,105Max[Transpose[eigenvecs[[1;;2]]^2]]}},PlotRangePadding->Scaled[.05],
AxesOrigin->{0,0},
Frame->{True,True,False,False},FrameStyle->Directive[Black,FontSize->15],FrameLabel->{
Style["Contrib. to F1 (%)",FontSize->16,Blue],
Style["Contrib. to F2 (%)",FontSize->16,Red]
}
],
(* no 2D loading plot: add "nothing" *)
Nothing
]
]
],

(***************)
(* 3D PLOTTING *)
(***************)

OptionValue[output]=="3D"||OptionValue[output]=="3DL",(* 3D plot of results was requested *)
plotdata=labeledtransformed[[All,1;;4]];

(* Swap values along x or y axes if requested; default is to do nothing *)
Module[
{xflip,yflip,zflip},
Switch[Length@OptionValue[swapaxes],

0, (* Atomic expression, i.e. a single value was passed *)
Switch[OptionValue[swapaxes],
True,xflip=yflip=zflip=-1,(* swap all axes *)
False,xflip=yflip=zflip=1,(* don't swap any axis *)
_,(* incorrect option; throw error and return Null *)Message[lda::swapaxesnotboolean,OptionValue[swapaxes]];Return[]
],

1,(* a list with one element; this is ambiguous and may be a syntax error on the part of the user; throw error *)
Message[lda::swapaxeslength,OptionValue[swapaxes]];Return[],

2,(* a list with two elements; not enough for a 3D plot; throw error *)
Message[lda::swapaxeslength,OptionValue[swapaxes]];Return[],

3,(* a list of three values*)
If[Not[BooleanQ@OptionValue[swapaxes][[1]]&&BooleanQ@OptionValue[swapaxes][[2]]&&BooleanQ@OptionValue[swapaxes][[3]]],Message[lda::swapaxesnotboolean,OptionValue[swapaxes]];Return[]];
xflip=If[OptionValue[swapaxes][[1]]===True,-1,1];
yflip=If[OptionValue[swapaxes][[2]]===True,-1,1];
zflip=If[OptionValue[swapaxes][[3]]===True,-1,1],

_,(* too many parameters for a 3D plot; possibly ambiguous *)
Message[lda::swapaxeslength,OptionValue[swapaxes]];Return[]
];

plotdata=plotdata/.List[class_?StringQ,x_?NumberQ,y_?NumberQ,z_?NumberQ]->List[class,xflip x,yflip y,zflip z]
];

(* Ellipsoids: see above in plot 2D for discussion of width of ellipsoids *)
partitionedscores=GatherBy[plotdata[[2;;]],First][[All,All,2;;4]];
ellipsoids3D={Opacity[0.1,Black],Ellipsoid[Mean[#],InverseCDF[ChiSquareDistribution[3],confidenceLevel]Covariance[#]]}&/@partitionedscores;
coloredellipsoids3D=MapThread[
{Opacity[0.2,#2],Ellipsoid[Mean[#1],InverseCDF[ChiSquareDistribution[3],confidenceLevel]Covariance[#1]]}&,
{
partitionedscores,
colorlist[[1;;First@Dimensions@partitionedscores]]
}];

readyforplot=MapThread[Tooltip[{#3,Point[#1]},#2]&,{partitionedscores,classlist,colorlist[[1;;First@Dimensions@partitionedscores]]}];

Return[
If[OptionValue[output]=="3DL",GraphicsRow[#,ImageSize->Scaled[1]]&,Show[#[[1]],ImageSize->Scaled[0.6]]&]@
List[
(* 3D score plot *)
Graphics3D[{
{PointSize->0.006,readyforplot},
Which[
OptionValue[ellipsoidcolor]===Automatic||OptionValue[ellipsoidcolor]===True,coloredellipsoids3D,
OptionValue[ellipsoidcolor]===False,ellipsoids3D,
True,Message[lda::ellcolor,OptionValue[ellipsoidcolor]];coloredellipsoids3D
]
},
Axes->True,AxesStyle->Black, BoxStyle->Black,
AxesLabel->{
Style["Factor 1 ("<>ToString[Round[100eigenvals[[1]]/Total@eigenvals,0.1]]<>"%)",FontSize->Scaled[0.04],FontFamily->"Arial",Blue],Style["Factor 2 ("<>ToString[Round[100eigenvals[[2]]/Total@eigenvals,0.1]]<>"%)",FontSize->Scaled[0.04],FontFamily->"Arial",Red],
Style["Factor 3 ("<>ToString[Round[100eigenvals[[3]]/Total@eigenvals,0.1]]<>"%)",FontSize->Scaled[0.04],FontFamily->"Arial",Darker@Green]
},
PlotRange->All,PlotRangePadding->Scaled[0.05],BoxRatios->{1, 1, 1},Lighting->"Neutral",RotationAction->"Clip"
],
If[OptionValue[output]=="3DL",
(* 3D loading plot *)
Graphics3D[
MapThread[Tooltip[Style[Point[#1],Red,PointSize[0.02]],Style[#2<>" "<>ToString@Round[100#1,1],Medium]]&,{Transpose[eigenvecs[[1;;3]]^2],columnheaderlist}],
PlotRange->{{0,1},{0,1},{0,1}},PlotRangePadding->Scaled[.05],
Axes->True,AxesStyle->Black, BoxStyle->Black,
AxesLabel->{
Style["Contrib. to F1",FontSize->Scaled[0.04],FontFamily->"Arial",Blue],
Style["Contrib. to F2",FontSize->Scaled[0.04],FontFamily->"Arial",Red],
Style["Contrib. to F3",FontSize->Scaled[0.04],FontFamily->"Arial",Darker@Green]
},
RotationAction->"Clip"
],
(* no 3D loading plot: add "nothing" *)
Unevaluated@Sequence[]
]
]
],

(************************************)
(* Default: incorrect output option *)
(************************************)

True,(* default option: if this is reached, the selected output option is incorrect, so throw error and return Null *)
Message[lda::outputoptions,OptionValue[output]];Return[]
];
]


(* This alternative definition of lda handles malformed input *)
lda::notamatrix="The input to lda is not a matrix.";
lda[dataset_/;Not[MatrixQ[dataset]],OptionsPattern[]]:=Message[lda::notamatrix]



(* ::Section::Initialization::Closed:: *)
(*pca: a PCA helper function*)


(* ::Input::Initialization:: *)
Options[pca]={output->"2DL",confidencelevel->0.95};

pca::outputoptions="The value `1` is not a valid plotting option. Valid options are: \"2DL\" (default), \"2D\", \"scores\", \"eigenvectors\", \"eigensystem\", \"vartable\", \"varlist\".";
pca::conflevel="`1` is an invalid value for the confidence level (0 < p < 1). The default 95% confidence level will be used instead.";

pca[data_?MatrixQ,options:OptionsPattern[]]:=
Module[
{
vars=data[[1,2;;]],
labels=data[[2;;,1]],
confidenceLevel,
scores,scores2D,annotated,scoregroups,
leftSingularValues,s,eigenvecsT,
eigenvals,eigenvecs
},

(*Set the confidence level for ellipsoid plotting*)
(*The deafult value is 0.95 for 95% confidence*)
(*Incorrect values trigger a message,but the calculation continues anyway,using the default 95% confidence level*)
confidenceLevel=With[{cf=OptionValue["confidencelevel"]},If[NumericQ[cf]&&0<cf<1,cf,Message[pca::conflevel,cf];0.95]];

(* results of singular value decomposition: {leftSingularValues, s, Transpose@rightSingularValues} *)
(* PCA scores = leftSingularValues.s *)

(* eigenVALUES of the correlation of data = diagonal elements of s^2/(number of variables - 1) *)
(* note that in most cases the normalization factor (number of variables - 1) can be ignored, because the eigenvalues will be renormalized anyway *)

(* the right singular values happen to be the eigenVECTORS of the correlation matrix of data *)
(* here they are indicated as eigenvecsT, because they are returned column-wise (i.e. each column of evecsT is an eigenvector) *)
(* think of it as: eigenvecsT = Transpose@Eigenvectors[Correlation@data]; ignoring sign changes, since sign is arbitrary anyway *)

{leftSingularValues,s,eigenvecsT}=SingularValueDecomposition[Standardize@data[[2;;,2;;]]];
eigenvals=Diagonal[s]^2;
scores=leftSingularValues . s;
scores2D=scores[[All,;;2]];
eigenvecs=Transpose@eigenvecsT;

annotated=Merge[Identity]@MapThread[
<|#1->Tooltip[#2,#1]|>&,
{labels,scores2D}
];
scoregroups=GatherBy[Transpose@Insert[Transpose@scores2D,labels,1],First][[All,All,2;;]];

(*********)
(* OUTPUT *)
(*********)

Which[
(* 2D plot of scores and loadings *)
OptionValue[output]=="2DL"||OptionValue[output]=="2D",
If[
OptionValue[output]==="2DL",
GraphicsRow[#,ImageSize->Scaled[2/3]]&,(*scores and loadings plots to be presented in a row*)
Show[#,ImageSize->Scaled[1/3]]&(*only the scores plot was requested, so just show it at proper size*)
]@{
(* PCA scores plot *)
ListPlot[
annotated,
PlotStyle->PointSize[0.015],
PlotLegends->None,
Frame->True,Axes->False,
PlotRangePadding->Scaled[.05],
LabelStyle->Directive[Black,16],
FrameStyle->Black,
FrameLabel->{
Style["PC1 ("<>ToString[Round[100eigenvals[[1]]/Total@eigenvals,0.1]]<>"%)",FontSize->16,Blue],
Style["PC2 ("<>ToString[Round[100eigenvals[[2]]/Total@eigenvals,0.1]]<>"%)",FontSize->16,Red]
},
AspectRatio->1,
(* the expansion factor for ellipsoids in n dimensions at confidence level p is given by InverseCDF[ChiSquareDistribution[n], p] *)
Epilog->{{Opacity[0],EdgeForm[Black],Ellipsoid[Mean[#],InverseCDF[ChiSquareDistribution[2], confidenceLevel]Covariance[#]]}&/@scoregroups}
](*end ListPlot for 2D PCA scores plot*),

If[OptionValue[output]=="2DL",
(* add 2D loadings plot *)
ListPlot[
MapThread[
(* old version: included contributions to PC1, PC2 in each label; however, we often remove these afterwards! *)
(*Labeled[100#1,Style[#2<>" "<>ToString@Round[100#1,0.1],Medium]]&,*)
(* new version only has measurement name; no longer includes the contributions *)
(* LabelVisibility priority calculated through Norm of the corresponding vector *)
(* this preferentially shows labels for contributions further away from the origin, i.e. more important *)
Labeled[100#1,Style[#2,Medium],LabelVisibility->Norm[#]]&,
{Transpose[eigenvecs[[1;;2]]^2],vars}
],
PlotStyle->Directive[Black,PointSize[0.025]],
(* The aspect ratio and plotrange definitions below make the plot square, while still adapting the plot range to the values being plotted *)
AspectRatio->1,
PlotRange->With[{max=105Max[Transpose[eigenvecs[[;;2]]^2]]},{{0,max},{0,max}}],
PlotRangePadding->Scaled[0.05],
AxesOrigin->{0,0},
Frame->{True,True,False,False},FrameStyle->Directive[Black,FontSize->15],
FrameLabel->{
Style["Contrib. to PC1 (%)",FontSize->16,Blue],
Style["Contrib. to PC2 (%)",FontSize->16,Red]
}
](*end ListPlot for loadings plot *),
(* 2D loading plot not requested: add "nothing" to the GraphicsRow *)
Nothing
](*end If*)
}
,


(* Return the transformed data as labeled SCORES, e.g. for external plotting *)
OptionValue[output]=="scores",
Transpose@Prepend[
(* Add the ROW headers from the original dataset back in *)
Transpose@Prepend[
(* Add the factor number COLUMN headers *)
scores,Array["PC"<>ToString[#]&,Dimensions[scores][[2]] ]
],
{""}~Join~labels
],


(* Return a formatted table of the contributions of each variable to the first three factors *)
OptionValue[output]=="vartable",
Style[
TableForm[Transpose@Round[100eigenvecs[[1;;3]]^2,0.1],TableHeadings->{vars, {"PC1","PC2","PC3"}},TableAlignments->Right],
FontFamily->"Arial",FontSize->14
],


(* Return the contributions of each variable to all factors, WITHOUT formatting *)
OptionValue[output]=="varlist",
Return[
Transpose@Join[{vars}, Round[100eigenvecs^2,0.1]]
],


(* Return eigenvector matrix *)
OptionValue[output]=="eigenvectors",
eigenvecs,


(* Return the list: {normalized eigenvalues, eigenvectors} *)
OptionValue[output]=="eigensystem",
{Normalize[eigenvals,Total],eigenvecs},

(* Output requested is invalid: print error message and abort *)
True,
Message[pca::outputoptions,OptionValue[output]];Abort[]

](*end Which*)
](*end Module*)


(* ::Section::Initialization::Closed:: *)
(*groupcontribs: group contribution helper functions*)


(* ::Input::Initialization:: *)
(* The following function generates a bar chart of the weighted contributions of each sensor to the overall discrimination *)
(* The contributions are weighted by the weight of the factors themselves, represented by the eigenvalues from lda *)
(* This is because a sensor that contributes a lot to an unimportant factor is still unimportant in the overall discrimination *)

groupcontribs::numgroups="The number of variables in the eigensystem (`1`) is not an exact multiple of the number of groups provided (`2`).";

groupcontribs[eigensystem_,numberofgroups_,sensornames_:Null]:=Module[
{eigenvals=eigensystem[[1]],eigenvecs=eigensystem[[2]],variablespergroup,sqweightedeigenvecs,barvalues},

If[Mod[Length@eigenvecs,numberofgroups]==0,
variablespergroup=(Length@eigenvecs)/numberofgroups,
Message[groupcontribs::numgroups,Length@eigenvecs,numberofgroups];Abort[]
];

(* eigenvectors are weighted by the corresponding eigenvalues, then squared *)
sqweightedeigenvecs=(Normalize[eigenvals,Total]eigenvecs)^2;

barvalues=Round[100#,1]&@
Normalize[#,Total]&@
Table[
Chop@Total[sqweightedeigenvecs[[All,i;;variablespergroup-1+i]]^2,Infinity],
{i,1,Last@Dimensions@eigenvecs-variablespergroup+1,variablespergroup}];

BarChart[
barvalues,
ChartLabels->Map[Style[#,FontSize->20,Black]&,If[sensornames===Null,Array[group,(Last@Dimensions@eigenvecs)/variablespergroup],sensornames]],
BarSpacing->Large,
PlotLabel->Style["% contribution of each sensor (overall)",Black,FontFamily->"Arial",FontSize->20],
ImageSize->Scaled[0.25]
]
]


(* ::Section::Initialization::Closed:: *)
(*outlierPCA: detection of outliers using PCA*)


(* ::Subsection:: *)
(*The "manual" version: shows all-data ellipsoid, lets user choose outliers*)


(* ::Text:: *)
(*The old outlierPCA used calculated the principal components using the eigensystem of the correlation of the data. *)
(*This was always VERY fragile, and had recently become the least dependable link in the toolchain.*)
(*This function has been rewritten (2017-06-26) to use the built-in PrincipalComponents[]. The built-in is much more robust, probably because it implements SVD or similar.*)
(**)
(*The manual version was finally superseded by the automatic one below in Dec 2018.*)
(*The main difference is in the fact that the automatic version plot an ellipsoid of confidence recalculated AFTER outlier removal, rather than plotting the ellipsoid corresponding to all data in a subset.*)


(* ::Subsection:: *)
(*The first automated version became standard in Dec 2018; it used to be called outlierPCAauto*)


(* ::Text:: *)
(*This version used the same machinery as the manual one, but it showed points outside of the original ellipsoid in red, then plotted data together with the ellipsoid that would be obtained if the alleged outliers were removed from the set.*)


(* ::Subsection:: *)
(*The newer recursive version, rewritten from scratch in Dec 2018*)


(* ::Text:: *)
(*Included upgrades:*)


(* ::Item:: *)
(*The aspect ratio of the plots was changed to automatic, so round ellipsoids would show up as round: the shape of the ellipsoid would therefore have meaning*)


(* ::Item:: *)
(*Recursion was implemented; outlierPCA now applies itself recursively to its own output, discarding points identified as outliers at each round, until there is no further change.*)


(* ::Item:: *)
(*The width of the ellipsoid that captures 95% of the points in n dimensions is approximated by*)
(*1.892 + 2.133 n - 0.06906 n^2 + 0.001985 n^3*)
(*This was arrived at separately (see the "making of recursive outlierPCA" notebook); it should still be replaced with an explicit reference to an appropriate chi-squared distribution.*)


(* ::Item:: *)
(*A new data structure is implemented to keep track of the position of replicates in the original data set. This also allows to share the whole dataset with each recursive call, so the whole dataset is returned at the end, partitioned in "inliers" and "outliers".*)


(* ::Item:: *)
(*A new data output is included, in which data is formatted as associations (output -> "Lists"), from which one can easily extract single sets, outliers, etc. See e.g. outlierPCA[data, output -> "Lists"]["Benzoate", "out"] that returns an association containing the outliers from the "Benzoate" labeled dataset, keyed with the respective replicate number from the original raw data set.*)


(* ::Item:: *)
(*By default, outlierPCA will do a single pass and return the plots; however, it can be set to recursive mode (the max number of recursive calls can also be set), and it can return a cleaned dataset.*)


(* ::Input::Initialization:: *)
outlierPCA::dimcaution="Using more than 3 dimensions for outlier detection may introduce too much noise";
outlierPCA::highdims="Dimensions requested are too high; limit to half the number of variables";
outlierPCA::nonnumdims="The value given for the dimensions option (`1`) was not recognized as an integer";
outlierPCA::method="An unrecognized method option (`1`) was used";
outlierPCA::output="An unrecognized output type was requested (`1`)";

(* default values for options *)
Options[outlierPCA]={dimensions->2,method->"SinglePass",output->"Plots",confidencelevel->0.95};

(* function definition to deal with data provided as lists ("old standard format") *)
(* restructureData returns a structured association, one of the keys being the list of variable names *)
(* that part is dropped here before passing the association on *)
outlierPCA[data_List?conditionsQ,options:OptionsPattern[]]:=outlierPCA[restructureData[data],options]

(* structured data provided, as a processed association *)
outlierPCA[data_Association,options:OptionsPattern[]]:=
Module[
{replicates,results,defaultMaxIterations=15},

(* for convenience, remove the variable names, because they are not needed for calculations *)
replicates=KeyDrop[data,"varnames"];

(* Check if dimensions is an integer; if not, get out; if it is, continue on and check its value *)
If[Not@IntegerQ@OptionValue[dimensions],Message[outlierPCA::nonnumdims,OptionValue[dimensions]];Return[]];
Which[
(* too many dimensions requested: abort computation: *)
OptionValue[dimensions]>Floor[Length@replicates[[1,1,2;;]]/2],(Message[outlierPCA::highdims];Return[]),
(* more than 3 dimensions requested: caution: *)
OptionValue[dimensions]>3,Message[outlierPCA::dimcaution]
];

(* Carry out actual calcuations *)
results=
Switch[OptionValue[method],
"SinglePass",iOutlierPCA[replicates,options],
"Recursive",FixedPoint[iOutlierPCA[#,options]&,replicates,defaultMaxIterations],
{"Recursive",_Integer|Infinity},FixedPoint[iOutlierPCA[#,options]&,replicates,OptionValue[method][[2]]],
_,(Message[outlierPCA::method,OptionValue[method]];Return[])(*option value not recognized*)
];

(* Generate output *)
Switch[OptionValue[output],
"Plots",KeyValueMap[iOutlierPlotter[#1,#2,options]&,results],
"Lists",results,
"OutlierLists",Keys/@results[[All,"out"]],
"CleanedSet",iRemakeDataset[Append[results,KeySelect[data,MatchQ["varnames"]]]],
_,(Message[outlierPCA::output,OptionValue[output]];Return[])(*option value not recognized*)
]
]

(* catch-all: syntax error of some kind *)
outlierPCA[___]:=(Message[outlierPCA::usage];Return[])



(******************)
(* HELPER FUNCTIONS *)
(******************)

(* data structure checker for outlierPCA definition*)
conditionsQ=(And[
VectorQ[#[[1,2;;]],StringQ],(* first row should contain instrumental variable names, as strings *)
VectorQ[#[[2;;,1]],StringQ],(* first column should contain sample labels names, as strings *)
MatrixQ[#[[2;;,2;;]],NumberQ](* the rest of the array should only contain numerical values *)
]&);

(* Data restructuring utility *)
ClearAll[restructureData]
restructureData[data_List?conditionsQ]:=
Append[
<|"in"->#,"out"->{}|>&/@GroupBy[
data[[2;;]],
First->Rest,
(* use the "combiner function" capability of GroupBy to do further processing: *)
(* add a counter label to each replicate in the grouped sets, *)
(* then organize them in an association *)
Association@*MapIndexed[First@#2->#1&]
],
"varnames"->data[[1,2;;]]
]

(* generating the region member functions *)
ClearAll[iOutlierPCA]
iOutlierPCA[structuredData_Association,options:OptionsPattern[{iOutlierPCA,outlierPCA}]]:=Module[
{pcas,labeledpcas,rmfs,selectors,keytake},

pcas=Chop[PrincipalComponents[#,Method->"Correlation"][[All,;;OptionValue[dimensions]]]]&/@Query[All,"in",Values]@structuredData;
labeledpcas=MapThread[AssociationThread[#1->#2]&,{Keys/@structuredData[[All,"in"]],pcas}];

(* The size of the 95% ellipsoid, in units of covariance, depends on the number of dimensions *)
(* The "expansion factor" is given by InverseCDF[ChiSquareDistribution[n], p] where n = number of dimensions, and 0 < p < 1 is the confidence level (e.g. 0.95 for 95%) *)
(* Note that, at high dimensions, the ellipsoid becomes so large that almost no points are rejected *)
rmfs=RegionMember[Ellipsoid[Mean[#],InverseCDF[ChiSquareDistribution[OptionValue[dimensions]],OptionValue[confidencelevel]]Covariance[Values@#]]]&/@labeledpcas;
selectors=MapThread[GroupBy[#1,#2,Keys]&,{labeledpcas,rmfs}];

keytake[{allinputforlabel_,selector_}]:=<|
"in"->KeyDrop[allinputforlabel["in"],selector[False]],
"out"->Association[allinputforlabel["out"],KeyTake[allinputforlabel["in"],selector[False]]]
|>;
Merge[{structuredData,selectors},keytake]
]

ClearAll[iOutlierPlotter]
iOutlierPlotter[label_String,setOfReplicates_Association,options:OptionsPattern[{iOutlierPlotter,outlierPCA}]]:=Module[
{(* list of internal variables *)
pcas,labeledpcas,
structuredData,
newEllipsoid,
inplot,outplot},

(* Calculate principal component scores using ALL data, both retained and rejected *)
pcas=PrincipalComponents[Values[Join@@setOfReplicates],Method->"Correlation"][[All,;;2]];

(* Add numerical labels to scores: *)
(* because ListPlot would later mis-interpret association data with numerical keys (see docs), *)
(* the numerical labels are turned to strings here in preparation for plotting; *)
(* it is most convenient to do it now because they are all available here in a flat list *)
labeledpcas=AssociationThread[ToString/@Keys[Join@@setOfReplicates]->pcas];

(* divide up the scores in "in" and "out" groups: *)
(* split up the score list in two sub-lists, according to the length of *)
(* the in and out groups in the input data to this function *)
structuredData=AssociationThread[{"in","out"}->TakeDrop[
labeledpcas,
Query["in",Length]@setOfReplicates]
];

(* generate new ellipsoid for plotting*)
(* The exact value of the confidence level multiplier is InverseCDF[ChiSquareDistribution[2], 0.95] = 5.991 *)
(* in 2D, a 95% confidence ellipsoid is roughly 6 covariances wide*)
(* Values needed here because Covariance can't handle the association as a single matrix*)
 newEllipsoid=Ellipsoid[Mean[structuredData["in"]],InverseCDF[ChiSquareDistribution[2], OptionValue[confidencelevel]]Covariance[Values@structuredData["in"]]];

(* Prepare plots: *)
(* the inplot carries all the graphics formatting options for the overall plot,*)
(* so they will be inherited by the other Graphics objects when combined in Show *)
(* Also, points are explicitly Labeled because otherwise ListPlot would use Callouts, *)
(* and the callout "tails" would make the plots too crowded *)
inplot=ListPlot[
KeyValueMap[Labeled[#2,#1]&,structuredData["in"]],
PlotStyle->Directive[Black,PointSize[0.015]],
PlotRange->All,PlotRangePadding->Scaled[0.2],
PlotLabel->Style[label,Bold,Red,18],
Axes->False,Frame->False,

(* the Automatic aspect ratio is a significant change from the previous outlierPCA *)
(* it should allow round-ish ellipsoids to actually show up round *)
(* and more generally it should allow for a more natural visual inspection of data spread *)
AspectRatio->Automatic,

(* the widths of the plots are constant at 1/4 window width; *)
(* height is then automatically calculated from the necessary aspect ratio *)
ImageSize->Scaled[0.25],
PlotLegends->None
];

outplot=ListPlot[
KeyValueMap[Labeled[#2,#1]&,structuredData["out"]],
PlotStyle->Directive[Red,PointSize[0.015]]
];

(* Combine plots with explicitly drawn ellipsoid *)
Framed@
Show[{
inplot,outplot,
Graphics[{FaceForm[None],EdgeForm[{Thick,Darker@Gray}],newEllipsoid}]},
PlotRange->All
]

]

ClearAll[iRemakeDataset]
iRemakeDataset[results_Association]:=Module[
{goodReplicates,flatTable,firstRow},

goodReplicates=Query[All,"in",Values]@KeyDrop["varnames"]@results;

(* Tuples was key here in "distributing" the sample labels to each replicate *)
flatTable=Flatten[#,1]&@KeyValueMap[Flatten/@Tuples[{{#1},#2}]&]@goodReplicates;

firstRow=Join[{""},results["varnames"]];

Join[{firstRow},flatTable]
]


(* ::Section::Initialization::Closed:: *)
(*selectVarSubsets: helper function to select homogeneous instrumental variable subsets for analysis*)


(* ::Input::Initialization:: *)
selectVarSubsets::emptystring="One of the criteria contains an empty string (\"\"). Check your input.";

selectVarSubsets[set_,""]:=(Message[selectVarSubsets::emptystring];Abort[])
selectVarSubsets[set_,c_Except]/;First[c]==="":=(Message[selectVarSubsets::emptystring];Abort[])
selectVarSubsets[set_,criterion_Alternatives?(MemberQ[""])]:=(Message[selectVarSubsets::emptystring];Abort[])

selectVarSubsets[set_,criterion_Except]:=Transpose[Select[Transpose[set],StringFreeQ[#1[[1]],First@criterion]&]]
selectVarSubsets[set_,criterion_]:=Transpose[Insert[Select[Transpose[set],StringContainsQ[#1[[1]],criterion]&],set[[All,1]],1]]
selectVarSubsets[set_,criteria_List]:=Fold[selectVarSubsets,set,criteria]


(* ::Section::Initialization::Closed:: *)
(*filterVars: helper function to use with Manipulate to interactively filter low-contribution variables to LDA*)


(* ::Input::Initialization:: *)
Options[filterVars]={output->"ReducedSet"};

filterVars::alldiscarded="The requested threshold is so high that all variables were removed from the dataset. Consider lowering it.";
filterVars::invopt="Incorrect option value; the only option allowed is output -> \"ReducedSet\".";

(* If function is called with only one argument, interactive manipulation is selected; the variable must be a dataset *)
filterVars[dataset_?(MatrixQ[#[[2;;,2;;]],NumberQ]&)]:=DynamicModule[
{threshold=0},(*Initially threshold is set to zero*)
Dynamic[
MapAt[(*MapAt wraps the bar chart received from iFilterVars in ClickPane and uses mouse clicks to adjust threshold*)
Function[plot,ClickPane[plot,(threshold=First@#)&]],
iFilterVars[dataset,threshold],
{1,2,1}(*position of the bar chart in the grid returned by iFilterVars*)
],
(*Only tracks changes in threshold; otherwise graphics are unresponsive and jittery*)
TrackedSymbols:>{threshold}
]
]

(* If function is called with two arguments, a dataset and a threshold, then a non-interactive single-value graphical results are returned *)
filterVars[dataset_?(MatrixQ[#[[2;;,2;;]],NumberQ]&),threshold_?NumericQ/;threshold>=0]:=iFilterVars[dataset,threshold]

(* If function is called with two arguments (i.e. dataset and threshold), and output \[Rule] "ReducedSet" is included, then a reduced data set is returned instead of graphical results *)
filterVars[dataset_?(MatrixQ[#[[2;;,2;;]],NumberQ]&),threshold_?NumericQ/;threshold>=0,OptionsPattern[]]:=Module[
{evals,evecs,assoc,selectedVars},

If[OptionValue[output]=!="ReducedSet",Message[filterVars::invopt];Abort[]];

{evals,evecs}=lda[dataset,applyfunc->Standardize,output->"eigensystem"];
assoc=AssociationThread[dataset[[1,2;;]],100Chop[Normalize[evals,Total] . evecs^2]];
selectedVars=Select[assoc,#>=threshold&];

(* Inform the user if the threshold is so high that all variables are discarded *)
If[Length[selectedVars]==0,Message[filterVars::alldiscarded]];

(*Collect and compile an output data set*)
Transpose@Join[{dataset[[All,1]]},Cases[Transpose@dataset,{Alternatives@@Keys[selectedVars],__}]]
]

(* Implementation code *)
ClearAll[iFilterVars]
iFilterVars[dataset_,threshold_]:=Module[
{assoc,selectedVars,selectedData,ldaplot,ldavarlist,bchart,evals,evecs},

{evals,evecs}=lda[dataset,applyfunc->Standardize,output->"eigensystem"];
assoc=AssociationThread[dataset[[1,2;;]],100Chop[Normalize[evals,Total] . evecs^2]];

selectedVars=Select[assoc,#>=threshold&];
selectedData=Transpose@Join[{dataset[[All,1]]},Cases[Transpose@dataset,{Alternatives@@Keys[selectedVars],__}]];

bchart=BarChart[
assoc,
BarOrigin->Left,ChartLabels->Automatic,BarSpacing->0.5,
ColorFunctionScaling->False,
ColorFunction->Function[{height},If[height>=threshold,Darker@Green,LightGray]],
AspectRatio->2,ImageSize->Large,
Prolog->{Dashing[0.02],Darker@Gray,Thick,HalfLine[{{threshold,0.3},{threshold,10}}]}
];

ldaplot=Show[
lda[selectedData,applyfunc->Standardize,output->"2D"],
ImageSize->Large];

ldavarlist=Reverse@SortBy[{#[[2]]&,#[[3]]&}]@lda[selectedData,applyfunc->Standardize,output->"varlist"][[All,1;;3]];

Grid[
{
(*formatting of titles: apply style only if argument is string; otherwise SpanFromLeft looks weird*)
Function[{s},If[Head[s]===String,Style[s,18,Black,FontFamily->"Trebuchet MS"],s]]/@
{"Original data set:",
SpanFromLeft,
"Filtered data set: (threshold = "<>ToString[Round[threshold,0.01]]<>")"},
{bchart,
selectedVars//Round[#,0.1]&//Sort//Reverse//Dataset,
ldaplot},
{SpanFromAbove,
Column[Style[#,Black,Bold,22]&/@{
"Retained:\n",
ToString@Length[selectedVars]<>" vars\n",
ToString@Round[Total@selectedVars,0.1]<>"% info"
},Right],
Multicolumn[ldavarlist,4(*organize results in four columns*)]}
},
Background->{None,None,{3,2}->LightGray},
Alignment->{Center,Center},
Dividers->{{3->Directive[Thick,Black]},{2->Directive[Thick,Black]}},
Spacings->{
(*x direction, add spacing btw table and new LDA plot's F2 axis label*){Automatic,3->Offset[1]},
(*y direction, add spacing btw titles and the new LDA plot's frame*){Automatic,2->Offset[1]}
}
]
]


(* ::Section::Closed:: *)
(*retainedInfo: a function to calculate the % retained information as a function of filter threshold*)


(* ::Input::Initialization:: *)
Options[retainedInfo]={output->"Plot"};

retainedInfo[dataset_,OptionsPattern[]]:=Module[{eigensystem},
eigensystem=lda[dataset,applyfunc->Standardize,output->"eigensystem"];
Switch[OptionValue[output],
"Plot",iRetainedInfoPlot[eigensystem],
"List",iRetainedInfoList[eigensystem],
_,Message[retainedInfo::usage];Abort[]
]
]

ClearAll[iRetainedInfo]
iRetainedInfo[{evals_,evecs_},threshold_]:=Module[
{infolist},
infolist=100Chop[Normalize[evals,Total] . evecs^2];
Quantity[Total@Select[infolist,#>=threshold&],"Percent"]
]

ClearAll[iRetainedInfoPlot]
iRetainedInfoPlot[{evals_,evecs_}]:=Module[{maxthreshold},
maxthreshold=Max[100Chop[Normalize[evals,Total] . evecs^2]];
Plot[
iRetainedInfo[{evals,evecs},t],{t,0,maxthreshold},
PlotRange->{Automatic,100},PlotRangePadding->{Scaled[0.02],{2,2}},
Axes->False,Frame->{{True,False},{True,False}},
FrameTicks->{Automatic,{#,ToString[#]<>"%"}&/@Range[0,100,20]},
FrameStyle->Directive[Black,14],
FrameLabel->(Style[#,18]&/@{"threshold to discard variables","info retained in reduced system"}),
ImageSize->Large
]
]

ClearAll[iRetainedInfoList]
iRetainedInfoList[{evals_,evecs_}]:=With[
{maxthreshold=Max[100Chop[Normalize[evals,Total] . evecs^2]]},
Table[{t,iRetainedInfo[{evals,evecs},t]},{t,0,maxthreshold,maxthreshold/200}]
]


(* ::Section::Closed:: *)
(*effectOfRemovingVariables*)


(* ::Text:: *)
(*A helper function that attempts to show graphically the effect of removing more and more variables from a dataset on the LDA scores plot. Since the function doesn't appear to be very useful, it is currently not exported from the package. It is also not protected.*)


(* ::Input::Initialization:: *)
Options[effectOfRemovingVariables]={output->"3D"};

effectOfRemovingVariables::syntax="incorrect syntax / argument count, or unrealistic argument value";

effectOfRemovingVariables[dataset_?MatrixQ,tmax_:15,numsteps_:3,OptionsPattern[]]/;(0<tmax<100&&numsteps>1):=Module[
{iterator={t,0,tmax,tmax/(numsteps-1)},assoclist,i},

assoclist=iEffectOfRemovingVariables[dataset,tmax,numsteps];

Switch[OptionValue[output],

"3D",
i=1;
Graphics3D[{
KeyValueMap[{ColorData[97][i++],Inset[Style[StringTake[#1,1],Bold,14],#2]}&,assoclist],
{Opacity[0.2],Table[InfinitePlane[{{t,0,0},{t,1,0},{t,1,1}}],Evaluate@iterator]}
},
PlotRange->All,PlotRangePadding->{0,Scaled[0.05],Scaled[0.05]},
AxesLabel->{Style["threshold",16,Black,Bold],"F1","F2"},
BoxRatios->{3, 1, 1},ImageSize->Large,
Lighting->{{"Ambient", Gray}},
Axes->True,AxesStyle->{Directive[Black,Bold,16],Automatic,Automatic}
],

"2D",
Replace[
KeyValueMap[
Framed@ListPlot[#2,PlotLabel->Style[#1,16,Red],PlotRange->All,Joined->True,Mesh->Full,Axes->False,AspectRatio->1]&,
assoclist[[All,All,2;;]]
],
Line[l_List]:>{Arrowheads->Medium,Arrow/@Partition[l,2,1]},
Infinity
],

_,Message[effectOfRemovingVariables::syntax];Message[effectOfRemovingVariables::usage]
]
]

effectOfRemovingVariables[___]:=(Message[effectOfRemovingVariables::syntax];Message[effectOfRemovingVariables::usage])


ClearAll[iEffectOfRemovingVariables]
iEffectOfRemovingVariables[dataset_,tmax_,numsteps_]:=Module[
{iterator={t,0,tmax,tmax/(numsteps-1)}},
Merge[Identity]@
Table[
Map[
Join[{t},#]&,
Mean/@GroupBy[First->Rest]@
lda[filterVars[dataset,t,output->"ReducedSet"],output->"scores"][[2;;,1;;3]]
],
Evaluate@iterator
]
]


(* ::Section::Initialization::Closed:: *)
(*removeOutliers: helper function to remove outlier points*)


(* ::Input::Initialization:: *)
removeOutliers::dups="Duplicate sample names found in list of points to remove";
removeOutliers::missing="One of the specified sample names does not exist in the full dataset: check spelling?";

removeOutliers[dataset_?MatrixQ][argseq:{_String,_List}..]:=Module[
{allSamplesInSet,listToRemove,datasetAsAssociation,removalRules},
listToRemove=List@argseq;
allSamplesInSet=DeleteDuplicates[dataset[[2;;,1]]];

(* Check for duplicate sample names in argseq *)
If[Not@*DuplicateFreeQ@listToRemove[[All,1]],Message[removeOutliers::dups];Abort[]];
(* Check for mis-spelled or otherwise non-matching sample names in argseq *)
If[allSamplesInSet~(Not@*ContainsAll)~listToRemove[[All,1]],Message[removeOutliers::missing];Abort[]];

datasetAsAssociation=GroupBy[dataset,First];

removalRules=Join[
AssociationThread[allSamplesInSet->ConstantArray[{},Length@allSamplesInSet]],
AssociationThread[Rule@@Transpose@listToRemove]
];

Join[
{dataset[[1]]},
Flatten[#,1]&@
KeyValueMap[datasetAsAssociation[#1][[Range[Length[datasetAsAssociation[#1]]]~Complement~#2]]&,removalRules]
]
]


(* ::Section::Initialization::Closed:: *)
(*overview: generates sparklines for each instrumental variable in the dataset, for quick identification of useless variables*)


(* ::Subsection:: *)
(*Added an alternative tabular output (March 2022)*)


(* ::Text:: *)
(*Reports on aggregate or group-wise statistics of each raw measurement to identify potentially bad values (overflow, too low, too high, too noisy) from the values themselves, which are otherwise not reported in the sparklines.*)
(*Changed the implementation approach to having two internal implementation functions selected by an "output" option. The function defaults to generation of sparklines when no option is given for backwards compatibility.*)


(* ::Subsection:: *)
(*Added a preliminary sorting of the dataset (September 2021)*)


(* ::Text:: *)
(*If replicates for the same sample are not contiguous in the raw data table, overview reported jumbled results. If row labels are present, the function first sorts the dataset by each row's first entry (i.e. the label) before constructing the plots.*)


(* ::Subsection:: *)
(*Barchart functionality (added in March 2020, commented out and removed in September 2021; code removed in March 2022)*)


(* ::Text:: *)
(*The existing overview showed a sparkline for each instrumental measurement in the dataset. *)
(*The added functionality generates a bar chart approximating the relative information content of each instrumental measurements.*)


(* ::Item:: *)
(*Using non-standardized data, a "standard deviation of replication" is determined for each instrumental variable, by calculating the standard deviation among replicates  of the same sample for that variable. We then take the maximum among those values as the most representative. Then we calculate the standard deviation of all measurements for a certain variable (total standard deviation).*)


(* ::Item:: *)
(*The ratio between these two indicates how much variability among samples there is in each measurement channel that is not induced by noise. For instance, if a measurement is constant through the data set (so it conveys no information) but it is naturally affected by large errors, it may show up as having "high variance", although that variance is mostly due to noise. *)


(* ::Item:: *)
(*All variables may be shown, but by default a threshold of 3 is used, i.e. only those variables are plotted that show intersample deviations that are larger than 3x the max intrasample deviation, with the assumptions that those with lower values are less important. *)


(* ::Input::Initialization:: *)
Options[overview]={output->"Sparklines"};

overview::wrongoption="The option `1` is not recognized. Valid output options are \"Sparklines\" (the default) and \"Table\".";

overview[data_?MatrixQ,OptionsPattern[]]:=
Switch[
OptionValue[output],
"Table",iOverviewTable[data],
"Sparklines",iOverviewSparklines[data],
_,Message[overview::wrongoption,OptionValue[output]]
]

ClearAll[iOverviewTable]
iOverviewTable[data_]:=Module[
{measurementNames,aggregateDescriptors,groupedDataDescriptors,combinedDescriptors,formattedDescriptors},

(* Take names of measurements from first row; remove the blank space in position 1,1 *)
measurementNames=data[[1,2;;]];

(* simple descriptive statistics on the entire dataset, measurement-wise *)
aggregateDescriptors={
Min[#],
Max[#],
Median[#],
Mean[#],
StandardDeviation[#]
}&/@Transpose[data][[2;;,2;;]];

(* medians by analyte *)
groupedDataDescriptors=
{##,#2-#1}&@@@
MinMax/@
Transpose@
Values[
Map[Median,#,{2}]&@
GroupBy[data[[2;;]],First->Rest,Transpose]
];

(* combine simple and grouped descriptors for each measurement in one row *)
combinedDescriptors=Flatten/@Transpose[{aggregateDescriptors,groupedDataDescriptors}];

(*format descriptors to align them on decimal point when in tabular form *)
formattedDescriptors=
Map[
PaddedForm[#,{6,3},NumberPadding->{" "," "},DigitBlock->3,NumberSeparator->"\[ThinSpace]"\[ThinSpace]]&,
combinedDescriptors,
{2}
];

(* Generate output *)
TableForm[
formattedDescriptors,
TableHeadings->{
measurementNames,
{
Tooltip["min","MINIMUM raw reading for this\nmeasurement across all samples"],
Tooltip["max","MAXIMUM raw reading for this\nmeasurement across all samples"],
Tooltip["median","MEDIAN reading for this\nmeasurement across all samples"],
Tooltip["ave","AVERAGE reading for this\nmeasurement across all samples"],
Tooltip["stdev","Standard deviation for this measurement across all samples"],
Tooltip["minMedian","smallest of the medians of\ngrouped replicates of each sample"],
Tooltip["maxMedian","largest of the medians of\ngrouped replicates of each sample"],
Tooltip["maxDeltaMedian","difference between the medians of the replicate set\nwith the highest vs. the lowest median value\nfor each measurement"]
}
},
TableAlignments->{Right,Center}
]
]

ClearAll[iOverviewSparklines]
iOverviewSparklines[data_]:=Module[
{workingdata,sparklines},

(*Check for the presence of sample labels, and remove them if present*)
(*Also stable-sort the dataset so replicates for the same sample are guaranteed to be contiguous*)
(*note! this works on the assumption that data[[1,1]] is an EMPTY STRING: otherwise the measurement names get alphabetized out of order*)
workingdata=If[StringQ@data[[2,1]],
(*the first column contains sample labels; use them to sort the dataset (except the first row, which are measurement labels and should not be touched)*)
(*1. remove first row and sort; 2. reattach first row; 2. remove sample labels*)
({data[[1]]}~Join~SortBy[data[[2;;]],{First}])[[All,2;;]],
(*there are no sample labels: nothing needs to be done*)
data
];

(* Build sparklines and organize them in a multicolumn display *)
sparklines=Multicolumn[
Framed[
ListPlot[
{##2},
PlotLabel->Style[#1,14,Red],
PlotRangePadding->{Scaled[0.03],{Scaled[0.05],Scaled[0.1]}},
Axes->None,
(*Do not display a frame around the plot area.
Although this is already the default for ListPlot,
let us just make sure, in case the default has been altered*)
Frame->None
]
]&@@@Transpose[workingdata],
Appearance->"Horizontal"
]
]


(* ::Section::Closed:: *)
(*projectorLDA: allows the projection of a second data set onto the LDA score plot generated  from the first one*)


(* ::Input::Initialization:: *)
(* The number of variables in the projector and projected set must be the same *)
projectorLDA::incompdims="The number of variables (i.e. columns) in the two sets is not the same.";

(* Base code *)
projectorLDA[projectorSet_?ArrayQ,projectorSuffix_String,projectedSet_?ArrayQ,projectedSuffix_String,options:OptionsPattern[lda]]:=Module[
{
projectedScoresAsTable,projectedScoresAsAssociation,
labelsForProjector,labelsForProjected,projectorSetRelabeled
},

If[Last@Dimensions[projectorSet]!=Last@Dimensions[projectedSet],Message[projectorLDA::incompdims];Abort[]];

(* Extract and modify labels to add suffixes *)
labelsForProjector=StringJoin[#,projectorSuffix]&/@projectorSet[[2;;,1]];
labelsForProjected=StringJoin[#,projectedSuffix]&/@projectedSet[[2;;,1]];

(* Relabel the projector set with the new labels to which the requested suffix has been added *)
projectorSetRelabeled=projectorSet;
projectorSetRelabeled[[2;;,1]]=labelsForProjector;

(* Calculate n-dimensional scores, then remove adventitious imaginary parts (Chop), then keep only first two dimensions *)
projectedScoresAsTable=Chop[
Standardize[ projectedSet[[2;;,2;;]] ] . Transpose[ lda[projectorSetRelabeled,output->"eigenvectors"] ]
][[All,;;2]];

projectedScoresAsAssociation=GroupBy[First->(Tooltip[Last[#],First[#]]&)]@Thread[labelsForProjected->projectedScoresAsTable];

Show[
(* use the usual LDA function to generate a base plot *)
(* this also includes the usual formatting and factor contribution calculations *)
lda[projectorSetRelabeled,output->"2D",ellipsoidcolor->True,options],
(* generate a second plot from the values *)
ListPlot[Values@projectedScoresAsAssociation]
]
]

(* Helper argument patterns that handle the various cases of missing suffixes *)
projectorLDA[projectorSet_?ArrayQ,projectorSuffix_String,projectedSet_?ArrayQ,options:OptionsPattern[lda]]:=projectorLDA[projectorSet,projectorSuffix,projectedSet,"",options]
projectorLDA[projectorSet_?ArrayQ,projectedSet_?ArrayQ,projectedSuffix_String,options:OptionsPattern[lda]]:=projectorLDA[projectorSet,"",projectedSet,projectedSuffix,options]
projectorLDA[projectorSet_?ArrayQ,projectedSet_?ArrayQ,options:OptionsPattern[lda]]:=projectorLDA[projectorSet,"",projectedSet,"",options]


(* ::Section::Closed:: *)
(*pairwiseScatterPlots:*)


(* ::Input::Initialization:: *)
pairwiseScatterPlot[dataset_?MatrixQ/;And@@NumberQ/@Flatten@dataset[[2;;,2;;]] ]:=Module[{varnames,correlation,data,plotfunction},

(*look for column headers or generate generic ones*)
(*this assumes that, if there are column headers, then there will also be row headers as well*)
If[Not@NumberQ@dataset[[1,2]],
varnames=dataset[[1,2;;]];data=dataset[[2;;,2;;]],
varnames=Array["var"<>ToString[#]&,Last@Dimensions[dataset]];data=dataset
];

(*calculate the correlation matrix*)
correlation=Correlation[data];

(*the plotting function, so it looks cleaner in the grid*)
plotfunction[i_,j_]:=
ListPlot[
data[[All,{i,j}]],
PlotRange->All,AspectRatio->1,Frame->True,FrameTicks->None,Axes->False,
Prolog->Inset[Style[NumberForm[correlation[[i,j]],{1,2}],FontColor->GrayLevel[.7],FontSize->Scaled[0.35]]],
Background->With[{corr=Abs@correlation[[i,j]]},Which[0<corr<0.5,Opacity[0.1,Green],0.5<=corr<=0.75,Opacity[0.1,White],corr>0.75,Opacity[0.1,Red]]]
];

(*generate the formatted output*)
Grid[
Table[
Which[
i<j,Null,
i==j,Graphics[Inset[Style[varnames[[i]],FontSize->Scaled[0.1]]],Background->GrayLevel[.85]],
i>j,plotfunction[i,j]
],
{i,Length[varnames]},{j,Length[varnames]}
]
]
]


(* ::Section::Closed:: *)
(*heatmap:*)


(* ::Input::Initialization:: *)
Options[heatmap]={
(* Pass-through options that are typically different from the default for MatrixPlot *)
AspectRatio->1/2,ImageSize->Full,
ColorFunction->Automatic,ColorFunctionScaling->True,
FrameTicksStyle->Directive[Black,9],
(* the default for plotting functions would be Automatic, rather than the following, but this is more convenient to handle options in the two directions separately *)
Mesh->{Automatic,None},MeshStyle->{Directive[GrayLevel[0,1],Thick],GrayLevel[0.5,0.5]},
(* option to decide whether the dataset should be sorted before plotting *)
"sortedSet"->True
};

heatmap[rawdata_,OptionsPattern[]]:=Module[
{sortedData,
measurements,varnames,samplenames,
meshLines,hMeshLines,vMeshLines,
ticks
},

Switch[OptionValue["sortedSet"],
True,sortedData=rawdata,
_,
(* In case the data set is not already pre-sorted, the sorting below ensures that: *)
(* 1) all replicates from same sample are together; *)
(* 2) measurements from the same sensors are grouped together *)
(* Point 2 requires that the first part of the measurement name be a sensor label (e.g. "ML A430"), which should be good practice anyway. *)
(* Both steps use a stable sort, so the original relative order of columns and rows is retained within each grouping: *)
(* for instance, replicates of the same sample are grouped, but within the group they will be in the same order as they were in the original dataset. *)
(* The ReplacePart ensures that the top left entry is an empty string, so the first row containins the measurement names will not be moved by Sort. *)
(* It would be safer to explicitly remove the first row before the first Sort, and re-append it later, but this should work as well. *)
sortedData=
Transpose@
SortBy[{First}]@Transpose@
SortBy[{First}]@
ReplacePart[rawdata,{1,1}->""]
];

measurements=sortedData[[2;;,2;;]];
varnames=sortedData[[1,2;;]];
samplenames=sortedData[[2;;,1]];

(* Position horizontal mesh lines between sets of replicates *)
(* Find the first occurrence of each sample name, then substract 1 because the mesh positions start at zero *)
(* For completeness, also add a line at the last position (the Join part) *)
hMeshLines=(Values[First/@PositionIndex[samplenames]]-1)~Join~{Length[samplenames]};
vMeshLines=Range[0,Length[varnames]];

meshLines=Switch[OptionValue[Mesh],
Automatic|{Automatic,Automatic},{hMeshLines,vMeshLines},
{Automatic,_},{hMeshLines,OptionValue[Mesh][[2]]},
{_,Automatic},{OptionValue[Mesh][[1]],vMeshLines},
_,OptionValue[Mesh]
];

(* Tick positions and labels *)
ticks=Module[{hTicks,vTicks},
hTicks=Transpose@{Range@Length[varnames],Rotate[#,90Degree]&/@varnames};
(* for vertical ticks, the Append part specifies outward-facing ("negative") tick marks but no inward-facing ones ("positive") *)
vTicks=Append[#,{0,0.003}]&/@Transpose@{MovingAverage[hMeshLines,2]+0.5,DeleteDuplicates[samplenames]};
{{vTicks,vTicks},{hTicks,hTicks}}(* {{left, right},{bottom, top}} *)
];

(* Generate the plot *)
MatrixPlot[
Standardize@measurements,
ColorFunction->OptionValue[ColorFunction],ColorFunctionScaling->OptionValue[ColorFunctionScaling],
PlotLegends->Placed[Automatic,Top],
ImageSize->OptionValue[ImageSize],
PlotRangePadding->None,
FrameTicks->ticks,FrameTicksStyle->OptionValue[FrameTicksStyle],
AspectRatio->OptionValue[AspectRatio],
Mesh->meshLines,MeshStyle->OptionValue[MeshStyle]
]
]



(* ::Section::Initialization::Closed:: *)
(*Closing out the package*)


(* ::Input::Initialization:: *)
End[];

Protect[addLabels,filterVars,groupcontribs,heatmap,lda,pairwiseScatterPlot,pca,projectorLDA,outlierPCA,overview,removeOutliers,retainedInfo,selectVarSubsets];

EndPackage[];
